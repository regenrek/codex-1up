# ~/.codex/config.toml  â€” SAFE

# Use the default OpenAI provider and model unless you override on the CLI.
model = "gpt-5-codex"
hide_agent_reasoning=false
model_reasoning_summary="auto"
show_raw_agent_reasoning=true

# Ask to escalate only if a command fails due to sandbox limits.
approval_policy = "on-failure"

# Writable only inside the workspace (and tmp). Still sandboxed.
sandbox_mode = "workspace-write"


[features]
web_search_request = true

[sandbox_workspace_write]
# Allow outbound network (package installs, git fetch, API calls) *inside* the sandbox.
# Keeps writes limited to the workspace and tmp; .git at repo root remains read-only.
network_access = true

[shell_environment_policy]
# Pass only core env (HOME, PATH, USER, etc.) to spawned subprocesses.
inherit = "core"
# Keep the default sensitive-name filter (KEY/SECRET/TOKEN) and add some common clouds.
exclude = ["AWS_*", "AZURE_*", "GCP_*", "GOOGLE_*", "OPENAI_*"]
# You can force-set safe overrides if needed:
# set = { CI = "1" }

# Optional privacy hardening:
# [history]
# persistence = "none"
